"use client";

import React, { useEffect, useRef, useState, useCallback } from "react";
import { useSearchParams } from "next/navigation";
import { v4 as uuidv4 } from "uuid";

import Image from "next/image";

// UI components
import Transcript from "./components/Transcript";
import Events from "./components/Events";
import BottomToolbar from "./components/BottomToolbar";

// Types
import { AgentConfig, SessionStatus } from "@/app/types";

// Context providers & hooks
import { useTranscript } from "@/app/contexts/TranscriptContext";
import { useEvent } from "@/app/contexts/EventContext";
import { useHandleServerEvent } from "./hooks/useHandleServerEvent";

// Utilities
import { createRealtimeConnection } from "./lib/realtimeConnection";
import {
  initAzureSpeechService,
  startAzureSpeechRecognition,
  stopAzureSpeechRecognition,
  updateTargetLanguage,
  disposeAzureSpeechService,
  registerAzureCallbacks
} from "./lib/azureSpeechService";
import { detectLanguage, updateLanguageState } from "./hooks/useHandleServerEvent";

// Agent configs
import { allAgentSets, defaultAgentSetKey } from "@/app/agentConfigs";

// æ·»åŠ è¯­è¨€ä»£ç åˆ°å‹å¥½åç§°çš„æ˜ å°„
const languageCodeToName: Record<string, string> = {
  'en': 'English',
  'es': 'Spanish',
  'zh': 'Chinese',
  'ja': 'Japanese',
  'ko': 'Korean',
  'ru': 'Russian',
  'fr': 'French',
  'de': 'German',
  'ar': 'Arabic',
  'hi': 'Hindi',
  'pt': 'Portuguese',
  'it': 'Italian',
  'nl': 'Dutch',
  'el': 'Greek',
  'th': 'Thai',
  'unknown': 'Unknown'
};

// è·å–å‹å¥½çš„è¯­è¨€åç§°
const getFriendlyLanguageName = (code: string): string => {
  // Handle when a full language name is passed instead of code
  if (code.length > 2) {
    // Check if code is already a language name 
    const isFullName = Object.values(languageCodeToName).includes(code);
    if (isFullName) return code;
    
    // Handle locale formats like 'en-US'
    const baseLang = code.split('-')[0].toLowerCase();
    return languageCodeToName[baseLang] || code;
  }
  
  return languageCodeToName[code] || code;
};

// æ·»åŠ windowç±»å‹æ‰©å±•
declare global {
  interface Window {
    lastTranscriptId: string | null;
    lastTranslationId: string | null;
  }
}

// åˆå§‹åŒ–å…¨å±€å˜é‡
if (typeof window !== 'undefined') {
  window.lastTranscriptId = null;
  window.lastTranslationId = null;
}

// æ·»åŠ ç±»å‹å®šä¹‰
type ServerEvent = {
  type: string;
  itemId?: string;
  status?: string;
  item_id?: string;
  transcript?: string;
  delta?: string;
  item?: {
    id: string;
    role: string;
    content?: Array<{
      type: string;
      text: string;
    }>;
  };
  response?: {
    output?: Array<{
      type: string;
      name?: string;
      call_id?: string;
      arguments?: any;
    }>;
  };
  session?: {
    id: string;
  };
};

function App() {
  const searchParams = useSearchParams();

  const { transcriptItems, addTranscriptMessage, addTranscriptBreadcrumb, updateTranscriptItemStatus, updateTranscriptMessage, toggleTranscriptItemExpand } =
    useTranscript();
  const { logClientEvent, logServerEvent } = useEvent();

  const [selectedAgentName, setSelectedAgentName] = useState<string>("");
  const [selectedAgentConfigSet, setSelectedAgentConfigSet] =
    useState<AgentConfig[] | null>(null);

  const [dataChannel, setDataChannel] = useState<RTCDataChannel | null>(null);
  const pcRef = useRef<RTCPeerConnection | null>(null);
  const dcRef = useRef<RTCDataChannel | null>(null);
  const audioElementRef = useRef<HTMLAudioElement | null>(null);
  const [sessionStatus, setSessionStatus] =
    useState<SessionStatus>("DISCONNECTED");

  const [isEventsPaneExpanded, setIsEventsPaneExpanded] =
    useState<boolean>(true);
  const [userText, setUserText] = useState<string>("");
  const [isPTTActive, setIsPTTActive] = useState<boolean>(true);
  const [isPTTUserSpeaking, setIsPTTUserSpeaking] = useState<boolean>(false);
  const [isAudioPlaybackEnabled, setIsAudioPlaybackEnabled] =
    useState<boolean>(true);
  const [mainLang, setMainLang] = useState<string>("zh");
  const [lastTargetLang, setLastTargetLang] = useState<string>("en");
  const [isFirstMessage, setIsFirstMessage] = useState<boolean>(true);

  // æ·»åŠ æŒ‡ä»¤æ›´æ–°é”å®šçŠ¶æ€
  const [isInstructionUpdating, setIsInstructionUpdating] = useState<boolean>(false);

  // æ·»åŠ è¿æ¥é‡è¯•è®¡æ•°å’Œå†·å´æœŸæ§åˆ¶
  const [connectionAttempts, setConnectionAttempts] = useState<number>(0);
  const [lastConnectionAttempt, setLastConnectionAttempt] = useState<number>(0);
  const MAX_CONNECTION_ATTEMPTS = 3;
  const CONNECTION_COOLDOWN_MS = 5000; // 5ç§’å†·å´æœŸ

  // æ·»åŠ Azureå®æ—¶è½¬å†™å’Œç¿»è¯‘çš„çŠ¶æ€
  const [azureInitialized, setAzureInitialized] = useState<boolean>(false);
  const [azureListening, setAzureListening] = useState<boolean>(false);
  const [realtimeTranscript, setRealtimeTranscript] = useState<string>("");
  const [realtimeTranslation, setRealtimeTranslation] = useState<string>("");
  const [realtimeFromLang, setRealtimeFromLang] = useState<string>("");
  const [realtimeToLang, setRealtimeToLang] = useState<string>("");
  
  // æ·»åŠ å®æ—¶æ¶ˆæ¯IDå¼•ç”¨ - åˆ†åˆ«ä¸ºè½¬å†™å’Œç¿»è¯‘
  const realtimeTranscriptMessageIdRef = useRef<string>("");
  const realtimeTranslationMessageIdRef = useRef<string>("");
  
  // å‡½æ•°ï¼šæ›´æ–°æˆ–åˆ›å»ºå®æ—¶è½¬å†™æ¶ˆæ¯ï¼ˆç”¨æˆ·ä¾§ï¼‰
  const updateRealtimeTranscriptMessage = () => {
    const existingId = realtimeTranscriptMessageIdRef.current;
    
    // æ„å»ºæ˜¾ç¤ºå†…å®¹ - åªåŒ…å«è½¬å†™
    let content = "";
    
    // æ·»åŠ è½¬å†™å†…å®¹
    if (realtimeTranscript && realtimeTranscript.trim()) {
      content = `${realtimeTranscript}`;
    } else {
      content = "æ­£åœ¨è†å¬...";
    }
    
    if (existingId && transcriptItems.some(item => item.itemId === existingId)) {
      // æ›´æ–°å·²æœ‰æ¶ˆæ¯
      updateTranscriptMessage(existingId, content, false);
    } else {
      // åˆ›å»ºæ–°æ¶ˆæ¯
      const newId = uuidv4().slice(0, 32);
      realtimeTranscriptMessageIdRef.current = newId;
      addTranscriptMessage(newId, "user", content);
    }
  };
  
  // å‡½æ•°ï¼šæ›´æ–°æˆ–åˆ›å»ºå®æ—¶ç¿»è¯‘æ¶ˆæ¯ï¼ˆagentä¾§ï¼‰
  const updateRealtimeTranslationMessage = () => {
    const existingId = realtimeTranslationMessageIdRef.current;
    
    // æ„å»ºæ˜¾ç¤ºå†…å®¹ - åªåŒ…å«ç¿»è¯‘
    let content = "";
    
    // æ·»åŠ è¯­è¨€æ ‡è¯†å’Œç¿»è¯‘å†…å®¹
    if (realtimeTranslation && realtimeTranslation.trim()) {
      content = `${realtimeTranslation}`;
    } else if (realtimeTranscript && realtimeTranscript.trim()) {
      content = "æ­£åœ¨ç¿»è¯‘...";
    } else {
      // å¦‚æœæ²¡æœ‰ä»»ä½•å†…å®¹ï¼Œä¸åˆ›å»ºæˆ–æ›´æ–°æ¶ˆæ¯
      return;
    }
    
    if (existingId && transcriptItems.some(item => item.itemId === existingId)) {
      // æ›´æ–°å·²æœ‰æ¶ˆæ¯
      updateTranscriptMessage(existingId, content, false);
    } else {
      // åˆ›å»ºæ–°æ¶ˆæ¯
      const newId = uuidv4().slice(0, 32);
      realtimeTranslationMessageIdRef.current = newId;
      addTranscriptMessage(newId, "assistant", content);
    }
  };

  const sendClientEvent = (eventObj: any, eventNameSuffix = "") => {
    if (dcRef.current && dcRef.current.readyState === "open") {
      logClientEvent(eventObj, eventNameSuffix);
      dcRef.current.send(JSON.stringify(eventObj));
    } else {
      logClientEvent(
        { attemptedEvent: eventObj.type },
        "error.data_channel_not_open"
      );
      console.error(
        "Failed to send message - no data channel available",
        eventObj
      );
    }
  };

  const handleServerEventRef = useCallback((event: ServerEvent) => {
    console.log("Received server event:", event);
    
    if (event.type === "status_update") {
      const { itemId, status } = event;
      console.log("Processing status update:", { itemId, status });
      
      if (status === "DONE") {
        console.log("Status is DONE, looking for message with itemId:", itemId);
        const message = transcriptItems.find(item => item.itemId === itemId);
        console.log("Found message:", message);
        
        if (message && message.role === "assistant") {
          console.log("Processing assistant message:", message);
          const content = event.item?.content?.[0]?.text || "";
          console.log("Message content:", content);
          
          // æ˜¾ç¤ºç¿»è¯‘ç»“æœ
          addTranscriptMessage(itemId || "", "assistant", content);
          
          // å¦‚æœå¯ç”¨äº†éŸ³é¢‘æ’­æ”¾ï¼Œæœ—è¯»ç¿»è¯‘ç»“æœ
          if (isAudioPlaybackEnabled) {
            // When English is detected, we should translate to Chinese (mainLang)
            // When Chinese is detected, we should translate to English (lastTargetLang)
            // Determine which language to use for TTS based on input language
            const messageLanguage = message.role === "assistant" ? 
              (realtimeFromLang === "en" || realtimeFromLang.startsWith("en-") ? "zh" : "en") : 
              lastTargetLang;
              
            console.log(`Playing TTS with language: ${messageLanguage}, detected from: ${realtimeFromLang}`);
            playTranslationTTS(content, messageLanguage);
          }
        }
      }
    } else if (event.type === "response.output_item.done" || event.type === "conversation.item.created") {
      // Process translation events from both response.output_item.done and conversation.item.created
      const itemId = event.item?.id;
      const content = event.item?.content?.[0]?.text || "";
      const role = event.item?.role || "";
      
      // Make sure this is an assistant message
      if (itemId && content && role === "assistant") {
        console.log(`Processing ${event.type} result:`, { itemId, content });
        
        // Always display translation in transcript
        addTranscriptMessage(itemId, "assistant", content);
        
        // å¦‚æœå¯ç”¨äº†éŸ³é¢‘æ’­æ”¾ï¼Œæœ—è¯»ç¿»è¯‘ç»“æœ
        if (isAudioPlaybackEnabled) {
          // When English is detected, we should translate to Chinese (mainLang)
          // When Chinese is detected, we should translate to English (lastTargetLang)
          // Determine which language to use for TTS based on input language
          const messageLanguage = role === "assistant" ? 
            (realtimeFromLang === "en" || realtimeFromLang.startsWith("en-") ? "zh" : "en") : 
            lastTargetLang;
            
          console.log(`Playing TTS with language: ${messageLanguage}, detected from: ${realtimeFromLang}`);
          playTranslationTTS(content, messageLanguage);
        }
      }
    } else if (event.type === "conversation.item.updated") {
      // Handle updated items, which may contain the latest translation
      const itemId = event.item?.id;
      const content = event.item?.content?.[0]?.text || "";
      const role = event.item?.role || "";
      
      if (itemId && content && role === "assistant") {
        console.log(`Processing updated message:`, { itemId, content });
        
        // Update the existing message or create a new one
        const existingMessage = transcriptItems.find(item => item.itemId === itemId);
        if (existingMessage) {
          updateTranscriptMessage(itemId, content, false);
        } else {
          addTranscriptMessage(itemId, "assistant", content);
        }
        
        // Play TTS for the updated content
        if (isAudioPlaybackEnabled) {
          // When English is detected, we should translate to Chinese (mainLang)
          // When Chinese is detected, we should translate to English (lastTargetLang)
          // Determine which language to use for TTS based on input language
          const messageLanguage = role === "assistant" ? 
            (realtimeFromLang === "en" || realtimeFromLang.startsWith("en-") ? "zh" : "en") : 
            lastTargetLang;
            
          console.log(`Playing TTS with language: ${messageLanguage}, detected from: ${realtimeFromLang}`);
          playTranslationTTS(content, messageLanguage);
        }
      }
    } else if (event.type === "conversation.item.input_audio_transcription.completed") {
      // Process transcription events with language detection
      const itemId = event.item_id;
      const transcript = event.transcript || "";
      
      if (itemId && transcript && transcript.trim() !== "" && transcript !== "\n") {
        console.log(`Processing transcription: "${transcript.substring(0, 30)}..."`);
        
        // Detect the language of the transcript
        if (transcript !== "[inaudible]") {
          detectLanguage(transcript).then(detectedLang => {
            if (detectedLang !== "unknown") {
              console.log(`Language detected in transcription: ${detectedLang}`);
              
              // Import the update function and use it
              updateLanguageState(
                detectedLang,
                isFirstMessage,
                setMainLang,
                setLastTargetLang,
                setIsFirstMessage,
                mainLang,
                lastTargetLang
              );
            }
          });
        }
      }
    }
  }, [transcriptItems, isAudioPlaybackEnabled, lastTargetLang, addTranscriptMessage, updateTranscriptMessage, updateTranscriptItemStatus, 
      mainLang, setMainLang, setLastTargetLang, isFirstMessage, setIsFirstMessage]);

  useEffect(() => {
    let finalAgentConfig = searchParams.get("agentConfig");
    if (!finalAgentConfig || !allAgentSets[finalAgentConfig]) {
      finalAgentConfig = defaultAgentSetKey;
      const url = new URL(window.location.toString());
      url.searchParams.set("agentConfig", finalAgentConfig);
      window.location.replace(url.toString());
      return;
    }

    const agents = allAgentSets[finalAgentConfig];
    const agentKeyToUse = agents[0]?.name || "";

    setSelectedAgentName(agentKeyToUse);
    setSelectedAgentConfigSet(agents);
  }, [searchParams]);

  useEffect(() => {
    if (selectedAgentName && sessionStatus === "DISCONNECTED") {
      connectToRealtime();
    }
  }, [selectedAgentName]);

  useEffect(() => {
    if (
      sessionStatus === "CONNECTED" &&
      selectedAgentConfigSet &&
      selectedAgentName
    ) {
      // ç¡®ä¿éŸ³é¢‘å…ƒç´ å·²æ·»åŠ åˆ°DOMå¹¶è®¾ç½®æ­£ç¡®
      if (audioElementRef.current && !document.body.contains(audioElementRef.current)) {
        audioElementRef.current.id = 'translator-audio-element';
        document.body.appendChild(audioElementRef.current);
        console.log("Audio element added to DOM");
      }
      
      const currentAgent = selectedAgentConfigSet.find(
        (a) => a.name === selectedAgentName
      );
      addTranscriptBreadcrumb(
        `Agent: ${selectedAgentName}`,
        currentAgent
      );
      
      // æ›´æ–°ä¼šè¯ï¼Œä½†ä¸å‘é€åˆå§‹"hi"æ¶ˆæ¯
      updateSession(false);
      
      // å»¶è¿Ÿå‘é€æ¬¢è¿æ¶ˆæ¯ï¼Œç¡®ä¿ä¼šè¯æ›´æ–°å·²å®Œæˆ
      setTimeout(() => {
        // ç”Ÿæˆå”¯ä¸€ID
        const welcomeId = uuidv4().slice(0, 32);
        
        // å‘é€æ¬¢è¿æ¶ˆæ¯äº‹ä»¶ä»¥è§¦å‘è¯­éŸ³åˆæˆ
        sendClientEvent(
          {
            type: "conversation.item.create",
            item: {
              id: welcomeId,
              type: "message",
              role: "assistant",
              content: [
                { 
                  type: "text", 
                  text: "Welcome to the Translator! I can translate in both directions: Chinese â†” English. Start speaking in either language, and I'll automatically detect and translate for you." 
                }
              ],
            },
          },
          "(send welcome message)"
        );
        
        // åœ¨UIä¸­æ˜¾ç¤ºæ¬¢è¿æ¶ˆæ¯
        addTranscriptMessage(
          welcomeId, 
          "assistant", 
          "Welcome to the Translator! I can translate in both directions: Chinese â†” English. Start speaking in either language, and I'll automatically detect and translate for you."
        );
        
        // æ›´æ–°æ¶ˆæ¯çŠ¶æ€ä¸ºå·²å®Œæˆ
        setTimeout(() => {
          updateTranscriptItemStatus(welcomeId, "DONE");
        }, 100);
      }, 500);
    }
  }, [selectedAgentConfigSet, selectedAgentName, sessionStatus]);

  useEffect(() => {
    if (sessionStatus === "CONNECTED") {
      console.log(
        `updatingSession, isPTTACtive=${isPTTActive} sessionStatus=${sessionStatus}`
      );
      updateSession();
    }
  }, [isPTTActive, mainLang, lastTargetLang]);

  const fetchEphemeralKey = async (): Promise<string | null> => {
    logClientEvent({ url: "/session" }, "fetch_session_token_request");
    const tokenResponse = await fetch("/api/session");
    const data = await tokenResponse.json();
    logServerEvent(data, "fetch_session_token_response");

    if (!data.client_secret?.value) {
      logClientEvent(data, "error.no_ephemeral_key");
      console.error("No ephemeral key provided by the server");
      setSessionStatus("DISCONNECTED");
      return null;
    }

    return data.client_secret.value;
  };

  const connectToRealtime = async () => {
    // æ·»åŠ è¿æ¥å°è¯•æ¬¡æ•°å’Œå†·å´æœŸæ£€æŸ¥
    const now = Date.now();
    if (connectionAttempts >= MAX_CONNECTION_ATTEMPTS && 
        now - lastConnectionAttempt < CONNECTION_COOLDOWN_MS) {
      console.log(`å·²è¾¾åˆ°æœ€å¤§è¿æ¥å°è¯•æ¬¡æ•°(${MAX_CONNECTION_ATTEMPTS})ï¼Œæ­£åœ¨å†·å´ä¸­...`);
      
      // æ˜¾ç¤ºè¿æ¥å¤±è´¥æ¶ˆæ¯
      addTranscriptMessage(
        uuidv4().slice(0, 32),
        "assistant", 
        "è¿æ¥å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œè¯·ç¨åå†è¯•æˆ–åˆ·æ–°é¡µé¢ã€‚"
      );
      
      return;
    }
    
    if (sessionStatus !== "DISCONNECTED") return;
    
    // æ›´æ–°è¿æ¥å°è¯•è®°å½•
    setConnectionAttempts(prev => prev + 1);
    setLastConnectionAttempt(now);
    
    // è®¾ç½®è¿æ¥çŠ¶æ€ä¸ºè¿æ¥ä¸­
    setSessionStatus("CONNECTING");
    console.log(`å¼€å§‹è¿æ¥åˆ°å®æ—¶API... (å°è¯• ${connectionAttempts + 1}/${MAX_CONNECTION_ATTEMPTS})`);

    try {
      const EPHEMERAL_KEY = await fetchEphemeralKey();
      if (!EPHEMERAL_KEY) {
        console.error("è·å–ä¸´æ—¶å¯†é’¥å¤±è´¥ï¼Œæ— æ³•è¿æ¥");
        setSessionStatus("DISCONNECTED");
        return;
      }

      // ä½¿ç”¨å·²æœ‰çš„éŸ³é¢‘å…ƒç´ ï¼Œè€Œä¸æ˜¯åˆ›å»ºæ–°çš„
      // é‡ç½®éŸ³é¢‘å…ƒç´ çŠ¶æ€
      if (audioElementRef.current) {
        console.log("é‡ç½®éŸ³é¢‘å…ƒç´ çŠ¶æ€");
        try {
          // æ–­å¼€ä»»ä½•ç°æœ‰è¿æ¥
          if (audioElementRef.current.srcObject) {
            console.log("æ–­å¼€ç°æœ‰éŸ³é¢‘æµ");
            audioElementRef.current.pause();
            audioElementRef.current.srcObject = null;
          }
          
          // ç¡®ä¿éŸ³é¢‘å±æ€§æ­£ç¡®è®¾ç½®
          audioElementRef.current.volume = 1.0;
          audioElementRef.current.muted = !isAudioPlaybackEnabled;
          
          console.log("éŸ³é¢‘å…ƒç´ å·²é‡ç½®å‡†å¤‡å¥½è¿æ¥æ–°æµ");
        } catch (e) {
          console.warn("é‡ç½®éŸ³é¢‘å…ƒç´ æ—¶å‡ºé”™:", e);
        }
      } else {
        console.error("æ‰¾ä¸åˆ°éŸ³é¢‘å…ƒç´ å¼•ç”¨ï¼Œæ— æ³•æ­£ç¡®è®¾ç½®éŸ³é¢‘");
      }

      console.log("å¼€å§‹åˆ›å»ºWebRTCè¿æ¥...");
      // åˆ›å»ºWebRTCè¿æ¥
      const { pc, dc } = await createRealtimeConnection(
        EPHEMERAL_KEY,
        audioElementRef
      );
      
      // è®¾ç½®æ•°æ®é€šé“é”™è¯¯å¤„ç†
      setupDataChannelHandlers(dc);
      
      console.log("WebRTCè¿æ¥åˆ›å»ºæˆåŠŸï¼Œè®¾ç½®äº‹ä»¶å¤„ç†...");
      
      // æ·»åŠ è¿æ¥çŠ¶æ€ç›‘æ§
      pc.onconnectionstatechange = () => {
        console.log(`WebRTCè¿æ¥çŠ¶æ€å˜æ›´: ${pc.connectionState}`);
        if (pc.connectionState === 'failed' || pc.connectionState === 'disconnected' || pc.connectionState === 'closed') {
          console.warn(`WebRTCè¿æ¥çŠ¶æ€å¼‚å¸¸: ${pc.connectionState}ï¼Œå‡†å¤‡é‡æ–°è¿æ¥`);
          setSessionStatus("DISCONNECTED");
        }
      };
      
      // æ”¹è¿›çš„ontrackäº‹ä»¶å¤„ç†
      pc.ontrack = (event) => {
        console.log("æ”¶åˆ°éŸ³é¢‘è½¨é“:", event.track.kind, event.track.id);
        
        if (event.streams && event.streams.length > 0) {
          const stream = event.streams[0];
          console.log("è·å–åˆ°éŸ³é¢‘æµ:", stream.id, "è½¨é“æ•°é‡:", stream.getTracks().length);
          
          // ç¡®ä¿éŸ³é¢‘å…ƒç´ å­˜åœ¨å¹¶è¿æ¥
          if (audioElementRef.current) {
            try {
              // æ–­å¼€ä»»ä½•ç°æœ‰è¿æ¥
              if (audioElementRef.current.srcObject) {
                console.log("æ–­å¼€ç°æœ‰éŸ³é¢‘æµ");
                audioElementRef.current.pause();
                audioElementRef.current.srcObject = null;
              }
              
              // è¿æ¥æ–°çš„éŸ³é¢‘æµ
              console.log("è¿æ¥æ–°çš„éŸ³é¢‘æµ");
              audioElementRef.current.srcObject = stream;
              
              // å¼ºåˆ¶æ’­æ”¾å¹¶å¤„ç†å¯èƒ½çš„é”™è¯¯
              const playPromise = audioElementRef.current.play();
              if (playPromise !== undefined) {
                playPromise.then(() => {
                  console.log("éŸ³é¢‘æ’­æ”¾å·²å¼€å§‹!");
                }).catch(error => {
                  console.error("è‡ªåŠ¨æ’­æ”¾è¢«é˜»æ­¢:", error);
                  
                  // åˆ›å»ºç”¨æˆ·æ¿€æ´»æ’­æ”¾çš„æŒ‰é’®
                  const playButton = document.createElement('button');
                  playButton.textContent = 'ç‚¹å‡»å¯ç”¨éŸ³é¢‘';
                  playButton.style.cssText = 'position:fixed; top:10px; right:10px; padding:8px 12px; background:#4CAF50; color:white; z-index:1000; border-radius:4px; font-weight:bold; box-shadow:0 2px 4px rgba(0,0,0,0.2);';
                  
                  playButton.onclick = () => {
                    if (audioElementRef.current) {
                      audioElementRef.current.play();
                      playButton.remove();
                    }
                  };
                  
                  document.body.appendChild(playButton);
                });
              }
            } catch (e) {
              console.error("è®¾ç½®éŸ³é¢‘æºå‡ºé”™:", e);
            }
          } else {
            console.error("éŸ³é¢‘å…ƒç´ ä¸å­˜åœ¨ï¼Œæ— æ³•è¿æ¥éŸ³é¢‘æµ");
          }
        } else {
          console.warn("æ”¶åˆ°è½¨é“ä½†æ²¡æœ‰å…³è”çš„æµ");
        }
      };

      pcRef.current = pc;
      dcRef.current = dc;

      // å¤„ç†æ•°æ®é€šé“æ‰“å¼€äº‹ä»¶
      dc.addEventListener("open", () => {
        console.log("æ•°æ®é€šé“å·²æ‰“å¼€ï¼Œè¿æ¥æˆåŠŸ");
        logClientEvent({}, "data_channel.open");
        setSessionStatus("CONNECTED");
        
        // æ•°æ®é€šé“æ‰“å¼€åï¼Œæ›´æ–°ä¼šè¯
        setTimeout(() => {
          updateSession();
        }, 500);
      });
      
      dc.addEventListener("close", () => {
        console.log("æ•°æ®é€šé“å·²å…³é—­");
        logClientEvent({}, "data_channel.close");
        setSessionStatus("DISCONNECTED");
      });
      
      dc.addEventListener("error", (err: any) => {
        console.error("æ•°æ®é€šé“é”™è¯¯:", err);
        logClientEvent({ error: err }, "data_channel.error");
        setSessionStatus("DISCONNECTED");
      });
      
      dc.addEventListener("message", (e: MessageEvent) => {
        handleServerEventRef(JSON.parse(e.data));
      });

      setDataChannel(dc);
    } catch (err) {
      console.error("è¿æ¥åˆ°å®æ—¶APIæ—¶å‡ºé”™:", err);
      setSessionStatus("DISCONNECTED");
    }
  };

  const disconnectFromRealtime = () => {
    if (pcRef.current) {
      pcRef.current.getSenders().forEach((sender) => {
        if (sender.track) {
          sender.track.stop();
        }
      });

      pcRef.current.close();
      pcRef.current = null;
    }
    setDataChannel(null);
    setSessionStatus("DISCONNECTED");
    setIsPTTUserSpeaking(false);

    logClientEvent({}, "disconnected");
  };

  const sendSimulatedUserMessage = (text: string) => {
    const id = uuidv4().slice(0, 32);
    addTranscriptMessage(id, "user", text, true);

    sendClientEvent(
      {
        type: "conversation.item.create",
        item: {
          id,
          type: "message",
          role: "user",
          content: [{ type: "input_text", text }],
        },
      },
      "(simulated user text message)"
    );
    sendClientEvent(
      { type: "response.create" },
      "(trigger response after simulated user text message)"
    );
  };

  const updateSession = (shouldTriggerResponse: boolean = false) => {
    try {
      sendClientEvent(
        { type: "input_audio_buffer.clear" },
        "clear audio buffer on session update"
      );
  
      const currentAgent = selectedAgentConfigSet?.find(
        (a) => a.name === selectedAgentName
      );
  
      const turnDetection = null;
  
      // æ›¿æ¢æŒ‡ä»¤ä¸­çš„å˜é‡å¹¶æ·»åŠ æ—¶é—´æˆ³ä»¥é¿å…ç¼“å­˜
      let instructions = currentAgent?.instructions || "";
      
      // åœ¨æŒ‡ä»¤å†…éƒ¨æ·»åŠ é‡ç½®æŒ‡ä»¤ï¼Œè€Œä¸æ˜¯é€šè¿‡å•ç‹¬çš„ç³»ç»Ÿæ¶ˆæ¯
      if (mainLang && lastTargetLang) {
        instructions = instructions.replace(/\${actualML}/g, mainLang);
        instructions = instructions.replace(/\${actualTL}/g, lastTargetLang);
        
        // æ·»åŠ æ—¶é—´æˆ³æ³¨é‡Šï¼Œå¼ºåˆ¶æ¨¡å‹é‡æ–°è§£ææŒ‡ä»¤
        const timestamp = Date.now();
        instructions += `\n\n// SYSTEM RESET: Translation settings updated at ${timestamp}`;
        instructions += `\n// IMPORTANT: From now on, translate: ML=${mainLang}, TL=${lastTargetLang}`;
      }
      
      console.log(`æ›´æ–°ä¼šè¯æŒ‡ä»¤: ML=${mainLang}, TL=${lastTargetLang}, æ—¶é—´æˆ³=${Date.now()}`);
  
      const tools = currentAgent?.tools || [];
  
      const sessionUpdateEvent = {
        type: "session.update",
        session: {
          modalities: ["text", "audio"],
          instructions,
          voice: "shimmer",
          input_audio_format: "pcm16",
          output_audio_format: "pcm16",
          input_audio_transcription: { model: "whisper-1" },
          turn_detection: turnDetection,
          tools,
        },
      };
  
      sendClientEvent(sessionUpdateEvent);
  
      if (shouldTriggerResponse) {
        sendSimulatedUserMessage("hi");
      }
    } catch (error) {
      console.error("æ›´æ–°ä¼šè¯æ—¶å‡ºé”™:", error);
    }
  };

  const cancelAssistantSpeech = async () => {
    const mostRecentAssistantMessage = [...transcriptItems]
      .reverse()
      .find((item) => item.role === "assistant" && item.status === "IN_PROGRESS");

    if (!mostRecentAssistantMessage) {
      console.log("No active assistant message to cancel");
      return;
    }
    
    // æ£€æŸ¥item_idæ˜¯å¦æœ‰æ•ˆï¼Œç¡®ä¿ä¸æ˜¯æˆªæ–­æˆ–æ— æ•ˆçš„ID
    if (!mostRecentAssistantMessage.itemId || 
        mostRecentAssistantMessage.itemId.length < 36 || 
        !mostRecentAssistantMessage.itemId.includes('-')) {
      console.warn("æ— æ•ˆçš„item_idï¼Œè·³è¿‡å–æ¶ˆè¯·æ±‚:", mostRecentAssistantMessage.itemId);
      return;
    }
    
    console.log("å–æ¶ˆåŠ©æ‰‹æ¶ˆæ¯:", mostRecentAssistantMessage.itemId);
    
    try {
      // å‘é€å–æ¶ˆè¯·æ±‚
      sendClientEvent({
        type: "conversation.item.truncate",
        item_id: mostRecentAssistantMessage.itemId,
        content_index: 0,
        audio_end_ms: Date.now() - mostRecentAssistantMessage.createdAtMs,
      });
      
      sendClientEvent(
        { type: "response.cancel" },
        "(cancel due to user interruption)"
      );
      
      // å‘ç”¨æˆ·æ˜¾ç¤ºæ¸…é™¤æŒ‡ç¤º
      addTranscriptBreadcrumb("å·²å–æ¶ˆåŠ©æ‰‹å›åº”");
      
    } catch (error) {
      console.error("Error canceling assistant speech:", error);
    }
  };

  const handleSendTextMessage = () => {
    if (!userText.trim()) return;
    
    try {
      cancelAssistantSpeech();
    } catch (error) {
      console.warn("å–æ¶ˆæ¶ˆæ¯æ—¶å‡ºé”™ï¼Œä½†ç»§ç»­å‘é€æ–°æ¶ˆæ¯:", error);
    }

    // æ¸…é™¤è¾“å…¥ç¼“å†²åŒºï¼Œé˜²æ­¢å†²çª
    sendClientEvent(
      { type: "input_audio_buffer.clear" },
      "clear PTT buffer"
    );

    sendClientEvent(
      {
        type: "conversation.item.create",
        item: {
          type: "message",
          role: "user",
          content: [{ type: "input_text", text: userText.trim() }],
        },
      },
      "(send user text message)"
    );
    setUserText("");

    sendClientEvent({ type: "response.create" }, "trigger response");
  };

  const handleTalkButtonDown = () => {
    // å¦‚æœæŒ‡ä»¤æ­£åœ¨æ›´æ–°ï¼Œé˜»æ­¢å½•éŸ³
    if (isInstructionUpdating) {
      console.log("æŒ‡ä»¤æ›´æ–°ä¸­ï¼Œè¯·ç¨å€™å†è¯•...");
      addTranscriptMessage(
        uuidv4().slice(0, 32),
        "assistant",
        "æŒ‡ä»¤æ›´æ–°ä¸­ï¼Œè¯·ç¨å€™å†è¯•..."
      );
      return;
    }
    
    // éªŒè¯è¿æ¥çŠ¶æ€
    const isConnected = sessionStatus === "CONNECTED";
    const isDataChannelOpen = dcRef.current?.readyState === "open";
    
    if (!isConnected || !isDataChannelOpen) {
      console.log(`æ— æ³•å¼€å§‹å½•éŸ³: è¿æ¥çŠ¶æ€=${sessionStatus}, æ•°æ®é€šé“çŠ¶æ€=${dcRef.current?.readyState || "æœªåˆ›å»º"}`);
      
      // å¦‚æœè¿æ¥å·²æ–­å¼€ï¼Œå°è¯•é‡æ–°è¿æ¥
      if (sessionStatus === "DISCONNECTED") {
        console.log("æ£€æµ‹åˆ°è¿æ¥å·²æ–­å¼€ï¼Œå°è¯•é‡æ–°è¿æ¥...");
        connectToRealtime();
        
        // æ˜¾ç¤ºé‡è¿æç¤º
        addTranscriptMessage(
          uuidv4().slice(0, 32),
          "assistant",
          "è¿æ¥å·²æ–­å¼€ï¼Œæ­£åœ¨å°è¯•é‡æ–°è¿æ¥ï¼Œè¯·ç¨åå†è¯•..."
        );
      } else if (sessionStatus === "CONNECTING") {
        // æ˜¾ç¤ºè¿æ¥ä¸­æç¤º
        addTranscriptMessage(
          uuidv4().slice(0, 32),
          "assistant",
          "æ­£åœ¨è¿æ¥ä¸­ï¼Œè¯·ç¨å€™..."
        );
      }
      return;
    }
    
    console.log("å¼€å§‹å½•éŸ³...");
    
    // æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒçš„åŠ©æ‰‹æ¶ˆæ¯éœ€è¦å–æ¶ˆ
    const hasActiveAssistantMessage = transcriptItems.some(
      item => item.role === "assistant" && item.status === "IN_PROGRESS"
    );
    
    // å¦‚æœæœ‰æ´»è·ƒçš„åŠ©æ‰‹æ¶ˆæ¯ï¼Œå…ˆå–æ¶ˆå®ƒ
    if (hasActiveAssistantMessage) {
      console.log("å–æ¶ˆæ´»è·ƒçš„åŠ©æ‰‹æ¶ˆæ¯");
      cancelAssistantSpeech();
    }

    // è®¾ç½®å½•éŸ³çŠ¶æ€ä¸ºæ´»è·ƒ
    setIsPTTUserSpeaking(true);
    
    // æ¸…ç©ºå½•éŸ³ç¼“å†²åŒº
    try {
      sendClientEvent({ type: "input_audio_buffer.clear" }, "clear PTT buffer");
    } catch (error) {
      console.error("æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒºé”™è¯¯:", error);
      setIsPTTUserSpeaking(false);
      
      // ä½¿ç”¨å®‰å…¨ç±»å‹æ¯”è¾ƒ
      if (sessionStatus !== "CONNECTED" && sessionStatus !== "CONNECTING") {
        console.log("å‘é€äº‹ä»¶å¤±è´¥ï¼Œå°è¯•é‡æ–°è¿æ¥...");
        
        // æ·»åŠ è¿æ¥å°è¯•æ§åˆ¶
        if (connectionAttempts < MAX_CONNECTION_ATTEMPTS) {
          disconnectFromRealtime();
          setTimeout(() => connectToRealtime(), 500);
        } else {
          addTranscriptMessage(
            uuidv4().slice(0, 32),
            "assistant", 
            "è¿æ¥å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•ã€‚"
          );
        }
      }
    }

    // å¼€å§‹Azureè¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘
    if (azureInitialized && !azureListening) {
      console.log("å¼€å§‹Azureå®æ—¶è½¬å†™å’Œç¿»è¯‘...");
      try {
        // ä½¿ç”¨æ›´é€šç”¨çš„è¯­è¨€ä»£ç è½¬æ¢å‡½æ•°
        const getLocaleFromCode = (code: string): string => {
          const localeMap: Record<string, string> = {
            'en': 'en-US',
            'zh': 'zh-CN',
            'es': 'es-ES',
            'fr': 'fr-FR',
            'de': 'de-DE',
            'ja': 'ja-JP',
            'ru': 'ru-RU',
            'ko': 'ko-KR',
            'ar': 'ar-SA',
            'pt': 'pt-BR',
            'it': 'it-IT'
          };
          
          if (code.includes('-')) return code;
          return localeMap[code.toLowerCase()] || 'en-US';
        };
        
        const targetLangCode = getLocaleFromCode(lastTargetLang);
        console.log(`Starting Azure speech recognition with target language: ${targetLangCode} (from ${lastTargetLang})`);
        
        // å¼ºåˆ¶æ ‡è®°è€æ¶ˆæ¯ä¸ºå®Œæˆ
        if (realtimeTranscriptMessageIdRef.current) {
          // å¦‚æœæœ‰ä¸Šä¸€è½®çš„æ¶ˆæ¯ï¼Œå°†å…¶æ ‡è®°ä¸ºå®Œæˆ
          updateTranscriptItemStatus(realtimeTranscriptMessageIdRef.current, "DONE");
        }
        
        if (realtimeTranslationMessageIdRef.current) {
          // å¦‚æœæœ‰ä¸Šä¸€è½®çš„æ¶ˆæ¯ï¼Œå°†å…¶æ ‡è®°ä¸ºå®Œæˆ
          updateTranscriptItemStatus(realtimeTranslationMessageIdRef.current, "DONE");
        }
        
        // å®Œå…¨æ¸…ç©ºå¼•ç”¨å’ŒçŠ¶æ€ - éå¸¸é‡è¦
        realtimeTranscriptMessageIdRef.current = "";
        realtimeTranslationMessageIdRef.current = "";
        
        // æ¸…ç©ºå®æ—¶è½¬å†™å’Œç¿»è¯‘ - ç¡®ä¿æ¯æ¬¡æ–°å½•éŸ³å®Œå…¨é‡ç½®çŠ¶æ€
        setRealtimeTranscript("");
        setRealtimeTranslation("");
        setRealtimeFromLang("");
        setRealtimeToLang("");
        
        // å¼ºåˆ¶åˆ›å»ºæ–°çš„ç©ºæ¶ˆæ¯ - ä¸ä¾èµ–äºè½¬å†™å’Œç¿»è¯‘çŠ¶æ€
        const newTranscriptId = uuidv4().slice(0, 32);
        realtimeTranscriptMessageIdRef.current = newTranscriptId;
        addTranscriptMessage(newTranscriptId, "user", "æ­£åœ¨è†å¬...");
        
        // åœ¨ç¡®ä¿åˆ›å»ºäº†æ–°æ¶ˆæ¯åå†å¯åŠ¨Azure
        setTimeout(() => {
          startAzureSpeechRecognition(targetLangCode, true);
          setAzureListening(true);
        }, 100);
      } catch (error) {
        console.error("å¯åŠ¨Azureè¯­éŸ³è¯†åˆ«å¤±è´¥:", error);
        setAzureListening(false);
      }
    } else if (!azureInitialized) {
      console.error("Azureè¯­éŸ³æœåŠ¡æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¼€å§‹å®æ—¶è½¬å†™");
    }
  };

  const handleTalkButtonUp = () => {
    if (!isPTTUserSpeaking) {
      console.log("Not currently recording, ignoring button up event");
      return;
    }
    
    console.log("Stopping recording...");
    
    // å…ˆè®¾ç½®çŠ¶æ€ä¸ºéå½•éŸ³çŠ¶æ€
    setIsPTTUserSpeaking(false);
    
    // å¦‚æœè¿æ¥å·²æ–­å¼€ï¼Œä¸å°è¯•å‘é€äº‹ä»¶
    if (sessionStatus !== "CONNECTED" || dataChannel?.readyState !== "open") {
      console.log("Cannot stop recording: not connected");
      return;
    }
    
    // åœæ­¢Azureè¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘
    if (azureInitialized && azureListening) {
      console.log("åœæ­¢Azureè¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘");
      stopAzureSpeechRecognition();
      setAzureListening(false);
      
      // è·å–å®æ—¶æ¶ˆæ¯ID
      const transcriptMessageId = realtimeTranscriptMessageIdRef.current;
      
      // å¦‚æœæœ‰è½¬å†™ç»“æœï¼Œå‘é€ç»™OpenAI
      if (realtimeTranscript && realtimeTranscript.trim()) {
        console.log("å‘é€æœ€ç»ˆè½¬å†™ç»“æœç»™OpenAI:", realtimeTranscript);
        
        try {
          // ä¿æŒå®æ—¶è½¬å†™æ¶ˆæ¯ä¸å˜ï¼Œä¸æ·»åŠ "å¤„ç†ä¸­"çŠ¶æ€
          if (transcriptMessageId) {
            // å°†çŠ¶æ€è®¾ä¸ºIN_PROGRESSä½†ä¸æ”¹å˜å†…å®¹
            updateTranscriptItemStatus(transcriptMessageId, "IN_PROGRESS");
          }
          
          // ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°å‘é€ç”¨æˆ·æ¶ˆæ¯ï¼Œä¸åˆ›å»ºæ–°æ¶ˆæ¯è€Œæ˜¯å¤ç”¨å®æ—¶æ¶ˆæ¯
          sendCustomUserMessage(realtimeTranscript, transcriptMessageId);
          
          return;
        } catch (error) {
          console.error("ä½¿ç”¨Azureè½¬å†™ç»“æœå‘é€æ¶ˆæ¯å¤±è´¥:", error);
        }
      } else {
        console.log("Azureæœªæä¾›æœ‰æ•ˆçš„è½¬å†™ç»“æœï¼Œå›é€€åˆ°OpenAIå¤„ç†");
        
        // å¦‚æœæœ‰å®æ—¶æ¶ˆæ¯ä½†æ²¡æœ‰æœ‰æ•ˆçš„è½¬å†™ç»“æœï¼Œéšè—å®æ—¶æ¶ˆæ¯
        if (transcriptMessageId) {
          updateTranscriptMessage(transcriptMessageId, "", false);
          updateTranscriptItemStatus(transcriptMessageId, "DONE");
          toggleTranscriptItemExpand(transcriptMessageId);
          realtimeTranscriptMessageIdRef.current = "";
        }
      }
    }
    
    try {
      // æäº¤å½•éŸ³ç¼“å†²åŒº
      sendClientEvent({ type: "input_audio_buffer.commit" }, "commit PTT");
      
      // å»¶è¿Ÿä¸€ç‚¹å†è§¦å‘å“åº”åˆ›å»ºï¼Œç¡®ä¿ç¼“å†²åŒºå·²æäº¤
      setTimeout(() => {
        sendClientEvent({ type: "response.create" }, "trigger response PTT");
      }, 200);
    } catch (error) {
      console.error("Error in handleTalkButtonUp:", error);
    }
  };

  // ä¿®æ”¹è‡ªå®šä¹‰å‘é€ç”¨æˆ·æ¶ˆæ¯å‡½æ•°
  const sendCustomUserMessage = (text: string, transcriptId: string) => {
    // å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„è½¬å†™æ¶ˆæ¯IDï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„æ¶ˆæ¯
    const messageId = transcriptId || uuidv4().slice(0, 32);
    
    // å¦‚æœæˆ‘ä»¬ä¸ä½¿ç”¨è½¬å†™æ¶ˆæ¯IDï¼Œæ·»åŠ ä¸€ä¸ªæ–°æ¶ˆæ¯
    if (!transcriptId) {
      addTranscriptMessage(messageId, "user", text, true);
    }

    // ä¿å­˜æ¶ˆæ¯IDï¼Œä»¥ä¾¿åœ¨æœåŠ¡å™¨å“åº”ä¸­ä½¿ç”¨
    if (typeof window !== 'undefined') {
      window.lastTranscriptId = transcriptId;
    }

    sendClientEvent(
      {
        type: "conversation.item.create",
        item: {
          id: messageId,
          type: "message",
          role: "user",
          content: [{ type: "input_text", text }],
        },
      },
      "(custom user text message)"
    );
    sendClientEvent(
      { type: "response.create" },
      "(trigger response after custom user text message)"
    );
  };

  const onToggleConnection = () => {
    if (sessionStatus === "CONNECTED" || sessionStatus === "CONNECTING") {
      disconnectFromRealtime();
      setSessionStatus("DISCONNECTED");
    } else {
      connectToRealtime();
    }
  };

  const handleAgentChange = (e: React.ChangeEvent<HTMLSelectElement>) => {
    const newAgentConfig = e.target.value;
    const url = new URL(window.location.toString());
    url.searchParams.set("agentConfig", newAgentConfig);
    window.location.replace(url.toString());
  };

  const handleSelectedAgentChange = (
    e: React.ChangeEvent<HTMLSelectElement>
  ) => {
    const newAgentName = e.target.value;
    setSelectedAgentName(newAgentName);
  };

  useEffect(() => {
    // Don't load isPTTActive from localStorage, always set to true
    const storedLogsExpanded = localStorage.getItem("logsExpanded");
    if (storedLogsExpanded) {
      setIsEventsPaneExpanded(storedLogsExpanded === "true");
    }
    const storedAudioPlaybackEnabled = localStorage.getItem(
      "audioPlaybackEnabled"
    );
    if (storedAudioPlaybackEnabled) {
      setIsAudioPlaybackEnabled(storedAudioPlaybackEnabled === "true");
    }
  }, []);

  useEffect(() => {
    localStorage.setItem("pushToTalkUI", isPTTActive.toString());
  }, [isPTTActive]);

  useEffect(() => {
    localStorage.setItem("logsExpanded", isEventsPaneExpanded.toString());
  }, [isEventsPaneExpanded]);

  useEffect(() => {
    localStorage.setItem(
      "audioPlaybackEnabled",
      isAudioPlaybackEnabled.toString()
    );
  }, [isAudioPlaybackEnabled]);

  // åœ¨MLæˆ–TLæ›´æ–°æ—¶æ›´æ–°ä¼šè¯è€Œä¸æ˜¯å¼ºåˆ¶æ–­å¼€é‡è¿
  useEffect(() => {
    if (sessionStatus === "CONNECTED" && (mainLang || lastTargetLang)) {
      console.log(`Language changed: ML=${mainLang}, TL=${lastTargetLang}`);
      
      // è®¾ç½®æŒ‡ä»¤æ›´æ–°é”å®šçŠ¶æ€
      setIsInstructionUpdating(true);
      
      // ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼ï¼šç›´æ¥æ›´æ–°ä¼šè¯è€Œä¸æ˜¯æ–­å¼€é‡è¿
      try {
        // å»¶è¿Ÿæ›´æ–°ä¼šè¯æŒ‡ä»¤ï¼Œç¡®ä¿çŠ¶æ€æ›´æ–°
        setTimeout(() => {
          // æ›´æ–°ä¼šè¯æŒ‡ä»¤è€Œä¸æ–­å¼€è¿æ¥
          updateSession();
          
          console.log("è¯­è¨€æ›´æ–°å®Œæˆï¼Œä¼šè¯å·²æ›´æ–°");
          
          // ç®€å•å»¶è¿Ÿåè§£é™¤é”å®š
          setTimeout(() => {
            setIsInstructionUpdating(false);
          }, 1000); 
        }, 500);
        
        // å¦‚æœå¤„äºå½•éŸ³çŠ¶æ€ï¼Œåœæ­¢å½•éŸ³ï¼ˆé¿å…çŠ¶æ€ä¸ä¸€è‡´ï¼‰
        if (isPTTUserSpeaking) {
          setIsPTTUserSpeaking(false);
        }
      } catch (err) {
        console.error("è¯­è¨€æ›´æ–°å¤±è´¥:", err);
        setIsInstructionUpdating(false);
      }
    }
  }, [mainLang, lastTargetLang]);

  // æ·»åŠ è¿æ¥çŠ¶æ€ç›‘æ§ï¼Œæœ‰é™åˆ¶åœ°å°è¯•é‡æ–°è¿æ¥
  useEffect(() => {
    if (sessionStatus === "DISCONNECTED" && selectedAgentName) {
      console.log("æ£€æµ‹åˆ°è¿æ¥æ–­å¼€ï¼Œè‡ªåŠ¨å°è¯•é‡æ–°è¿æ¥...");
      
      // æ·»åŠ è¿æ¥å°è¯•é™åˆ¶
      if (connectionAttempts < MAX_CONNECTION_ATTEMPTS) {
        const reconnectTimer = setTimeout(() => {
          connectToRealtime();
        }, 1000);
        
        return () => clearTimeout(reconnectTimer);
      } else {
        // å¦‚æœè¶…è¿‡æœ€å¤§å°è¯•æ¬¡æ•°ï¼Œæ˜¾ç¤ºé”™è¯¯å¹¶æç¤ºåˆ·æ–°
        if (Date.now() - lastConnectionAttempt > CONNECTION_COOLDOWN_MS) {
          // å†·å´æœŸç»“æŸåé‡ç½®å°è¯•è®¡æ•°
          setConnectionAttempts(0);
        } else {
          console.log("å·²è¾¾åˆ°æœ€å¤§é‡è¿æ¬¡æ•°ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•");
        }
      }
    }
  }, [sessionStatus, selectedAgentName, connectionAttempts]);

  // æ·»åŠ é‡ç½®è¿æ¥è®¡æ•°çš„æœºåˆ¶
  useEffect(() => {
    if (sessionStatus === "CONNECTED") {
      // è¿æ¥æˆåŠŸåé‡ç½®å°è¯•è®¡æ•°
      setConnectionAttempts(0);
    }
  }, [sessionStatus]);

  // æ·»åŠ éŸ³é¢‘æ’­æ”¾çŠ¶æ€ç›‘å¬
  useEffect(() => {
    if (audioElementRef.current) {
      const audioEl = audioElementRef.current;
      
      // æ·»åŠ éŸ³é¢‘äº‹ä»¶ç›‘å¬
      const onPlay = () => {
        console.log("éŸ³é¢‘å¼€å§‹æ’­æ”¾");
        // æ’­æ”¾æˆåŠŸæ—¶æ˜¾ç¤ºæç¤º
        addTranscriptMessage(
          uuidv4().slice(0, 32),
          "assistant",
          "ğŸ”Š Audio enabled, you can now hear voice output"
        );
      };
      const onPause = () => console.log("éŸ³é¢‘æš‚åœ");
      const onEnded = () => console.log("éŸ³é¢‘æ’­æ”¾ç»“æŸ");
      const onError = (e: any) => {
        console.error("éŸ³é¢‘æ’­æ”¾é”™è¯¯:", e);
        // æ’­æ”¾å¤±è´¥æ—¶æ˜¾ç¤ºæç¤º
        addTranscriptMessage(
          uuidv4().slice(0, 32),
          "assistant",
          "âš ï¸ Audio playback failed, please click the 'Play Audio' button to enable sound manually"
        );
      };
      
      audioEl.addEventListener('play', onPlay);
      audioEl.addEventListener('pause', onPause);
      audioEl.addEventListener('ended', onEnded);
      audioEl.addEventListener('error', onError);
      
      return () => {
        // æ¸…ç†äº‹ä»¶ç›‘å¬
        audioEl.removeEventListener('play', onPlay);
        audioEl.removeEventListener('pause', onPause);
        audioEl.removeEventListener('ended', onEnded);
        audioEl.removeEventListener('error', onError);
      };
    }
  }, []);

  useEffect(() => {
    if (audioElementRef.current) {
      audioElementRef.current.muted = !isAudioPlaybackEnabled;
      
      if (isAudioPlaybackEnabled) {
        audioElementRef.current.play().catch((e) => {
          console.warn("å¯ç”¨éŸ³é¢‘æ’­æ”¾å¤±è´¥:", e);
        });
      } else {
        audioElementRef.current.pause();
      }
    }
  }, [isAudioPlaybackEnabled]);

  // æ·»åŠ ä¸€ä¸ªå‡½æ•°æ¥ç®¡ç†éŸ³é¢‘çŠ¶æ€
  const tryToPlayAudio = () => {
    if (!audioElementRef.current) return;
    
    try {
      console.log("å°è¯•æ’­æ”¾éŸ³é¢‘");
      audioElementRef.current.muted = false;
      setIsAudioPlaybackEnabled(true);
      
      const playPromise = audioElementRef.current.play();
      if (playPromise !== undefined) {
        playPromise
          .then(() => console.log("éŸ³é¢‘æ’­æ”¾æˆåŠŸ!"))
          .catch(err => {
            console.error("è‡ªåŠ¨æ’­æ”¾è¢«é˜»æ­¢:", err);
            
            // æ˜¾ç¤ºæ’­æ”¾æç¤º
            addTranscriptMessage(
              uuidv4().slice(0, 32),
              "assistant",
              "Please click the 'Play Audio' button on the interface to enable sound"
            );
          });
      }
    } catch (err) {
      console.error("æ’­æ”¾éŸ³é¢‘å‡ºé”™:", err);
    }
  };

  // ç›‘å¬éŸ³é¢‘çŠ¶æ€å˜åŒ–
  useEffect(() => {
    // å½“è¿æ¥çŠ¶æ€å˜ä¸ºå·²è¿æ¥æ—¶ï¼Œå°è¯•æ’­æ”¾éŸ³é¢‘
    if (sessionStatus === "CONNECTED") {
      // å»¶è¿Ÿä¸€ç‚¹ï¼Œç¡®ä¿è¿æ¥å’ŒéŸ³é¢‘æµéƒ½å·²å°±ç»ª
      setTimeout(tryToPlayAudio, 1000);
    }
  }, [sessionStatus]);

  const agentSetKey = searchParams.get("agentConfig") || "default";

  // æ·»åŠ å…¨å±€é”™è¯¯å¤„ç†
  useEffect(() => {
    const handleWebRTCError = (event: any) => {
      console.error("WebRTCé”™è¯¯:", event);
      
      // æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯ç»™ç”¨æˆ·
      if (event.error?.message) {
        addTranscriptBreadcrumb(`è¿æ¥é”™è¯¯: ${event.error.message}`);
      }
    };
    
    // ç›‘å¬å…¨å±€é”™è¯¯
    window.addEventListener('error', handleWebRTCError);
    
    return () => {
      window.removeEventListener('error', handleWebRTCError);
    };
  }, []);

  // æ·»åŠ æ•°æ®é€šé“å¤„ç†æœºåˆ¶
  const setupDataChannelHandlers = (dataChannel: RTCDataChannel) => {
    // æ•°æ®é€šé“é”™è¯¯å¤„ç†
    dataChannel.onerror = (error) => {
      console.error("æ•°æ®é€šé“é”™è¯¯:", error);
      addTranscriptBreadcrumb(`æ•°æ®é€šé“é”™è¯¯: ${JSON.stringify(error)}`);
    };
    
    // ç›‘æ§æ•°æ®é€šé“æ¶ˆæ¯
    const originalOnmessage = dataChannel.onmessage;
    dataChannel.onmessage = (event) => {
      try {
        // å°è¯•è§£ææ¶ˆæ¯
        const data = JSON.parse(event.data);
        
        // æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if (data.type === "error") {
          console.error("æ”¶åˆ°APIé”™è¯¯:", data);
          
          // æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯ç»™ç”¨æˆ·
          addTranscriptBreadcrumb(`APIé”™è¯¯: ${data.error?.message || 'æœªçŸ¥é”™è¯¯'}`);
          
          // å¦‚æœæ˜¯item_idç›¸å…³é”™è¯¯ï¼Œè®°å½•ä»¥ä¾¿è°ƒè¯•
          if (data.error?.code === "item_truncate_invalid_item_id") {
            console.warn("æ— æ•ˆitem_idé”™è¯¯:", data.error.message);
          }
        }
      } catch (e) {
        // å¦‚æœä¸æ˜¯JSONæ•°æ®ï¼Œä½¿ç”¨åŸå§‹å¤„ç†å™¨
      }
      
      // è°ƒç”¨åŸå§‹çš„æ¶ˆæ¯å¤„ç†å™¨
      if (originalOnmessage) {
        originalOnmessage.call(dataChannel, event);
      }
    };
  };

  // ä¿®æ”¹Azureè¯­éŸ³å›è°ƒå‡½æ•°å¤„ç†
  useEffect(() => {
    if (azureInitialized) {
      // å®šä¹‰è½¬å†™å’Œç¿»è¯‘çš„å›è°ƒå‡½æ•°
      const handleTranscription = (result: { text: string; language: string; isFinal: boolean }) => {
        console.log(`Azure è½¬å†™: ${result.text}, æ˜¯æœ€ç»ˆç»“æœ: ${result.isFinal}`);
        
        // å§‹ç»ˆä½¿ç”¨æœ€æ–°çš„è½¬å†™ç»“æœæ›´æ–°çŠ¶æ€
        setRealtimeTranscript(result.text);
        setRealtimeFromLang(result.language);
        
        // å¯¹äºç©ºç»“æœæˆ–è€…åˆå§‹ç»“æœï¼Œç¡®ä¿ä½¿ç”¨æç¤ºæ–‡æœ¬
        if (!result.text || result.text.trim() === "") {
          // å¼ºåˆ¶æ›´æ–°ä¸ºæç¤ºæ–‡æœ¬
          if (realtimeTranscriptMessageIdRef.current) {
            updateTranscriptMessage(realtimeTranscriptMessageIdRef.current, "æ­£åœ¨è†å¬...", false);
          }
        } else if (realtimeTranscriptMessageIdRef.current) {
          // å¯¹äºæœ‰å†…å®¹çš„ç»“æœï¼Œç›´æ¥æ›´æ–°æ¶ˆæ¯
          updateTranscriptMessage(realtimeTranscriptMessageIdRef.current, result.text, false);
        }
      };
      
      const handleTranslation = (result: { 
        originalText: string; 
        translatedText: string; 
        fromLanguage: string; 
        toLanguage: string; 
        isFinal: boolean 
      }) => {
        // Update the translation state
        console.log(`Azure ç¿»è¯‘: ${result.translatedText}, ä» ${result.fromLanguage} åˆ° ${result.toLanguage}`);
        setRealtimeTranslation(result.translatedText);
        setRealtimeToLang(result.toLanguage);
        
        // Display the translation in the UI if it's a final result
        if (result.isFinal && result.translatedText.trim()) {
          // Create a new ID for the translation message if we don't have one
          if (!realtimeTranslationMessageIdRef.current) {
            realtimeTranslationMessageIdRef.current = uuidv4().slice(0, 32);
          }
          
          // Add the translation to the transcript
          addTranscriptMessage(
            realtimeTranslationMessageIdRef.current,
            "assistant",
            result.translatedText
          );
          
          // Play TTS for the translation but don't create a duplicate message
          if (isAudioPlaybackEnabled) {
            // When English is detected, we should use Chinese voice for TTS
            // When Chinese is detected, we should use English voice for TTS
            const detectedLang = result.fromLanguage.split('-')[0].toLowerCase();
            const ttsLanguage = detectedLang === 'en' ? 'zh' : 'en';
            
            console.log(`Playing TTS with language: ${ttsLanguage} based on detected: ${detectedLang}`);
            playTranslationTTS(result.translatedText, ttsLanguage);
          }
          
          // Silently detect and update language settings without notifications
          if (result.fromLanguage) {
            const detectedLang = result.fromLanguage.split('-')[0].toLowerCase();
            
            // Only update languages if they're different from current
            if (detectedLang === 'zh' && mainLang !== 'zh') {
              console.log(`Detected Chinese input, silently updating languages: ML=zh, TL=en`);
              setMainLang('zh');
              setLastTargetLang('en');
              
              // Update Azure service silently
              const getLocaleFromCode = (code: string): string => {
                const localeMap: Record<string, string> = {
                  'en': 'en-US', 'zh': 'zh-CN', 'es': 'es-ES',
                  'fr': 'fr-FR', 'de': 'de-DE', 'ja': 'ja-JP',
                  'ru': 'ru-RU', 'ko': 'ko-KR', 'ar': 'ar-SA',
                  'pt': 'pt-BR', 'it': 'it-IT'
                };
                if (code.includes('-')) return code;
                return localeMap[code.toLowerCase()] || 'en-US';
              };
              
              updateTargetLanguage(getLocaleFromCode('en'));
            } else if (detectedLang === 'en' && mainLang !== 'en') {
              console.log(`Detected English input, silently updating languages: ML=en, TL=zh`);
              setMainLang('en');
              setLastTargetLang('zh');
              
              // Update Azure service silently
              const getLocaleFromCode = (code: string): string => {
                const localeMap: Record<string, string> = {
                  'en': 'en-US', 'zh': 'zh-CN', 'es': 'es-ES',
                  'fr': 'fr-FR', 'de': 'de-DE', 'ja': 'ja-JP',
                  'ru': 'ru-RU', 'ko': 'ko-KR', 'ar': 'ar-SA',
                  'pt': 'pt-BR', 'it': 'it-IT'
                };
                if (code.includes('-')) return code;
                return localeMap[code.toLowerCase()] || 'en-US';
              };
              
              updateTargetLanguage(getLocaleFromCode('zh'));
            }
          }
        }
      };
      
      // æ³¨å†Œå›è°ƒå‡½æ•°åˆ°AzureæœåŠ¡
      registerAzureCallbacks(handleTranscription, handleTranslation);
    }
  }, [azureInitialized, isAudioPlaybackEnabled]);

  // åˆå§‹åŒ–Azureè¯­éŸ³æœåŠ¡
  useEffect(() => {
    const initAzure = async () => {
      console.log("æ­£åœ¨åˆå§‹åŒ–Azureè¯­éŸ³æœåŠ¡...");
      try {
        const success = await initAzureSpeechService(
          // è½¬å†™å›è°ƒ
          (result) => {
            console.log("æ”¶åˆ°Azureè½¬å†™ç»“æœ:", result);
            // æ›´æ–°å®æ—¶è½¬å†™
            setRealtimeTranscript(result.text);
            if (result.language && result.language !== 'unknown') {
              setRealtimeFromLang(result.language);
            }
            
            // å¦‚æœæ˜¯æœ€ç»ˆç»“æœï¼Œå‘é€åˆ°OpenAIè¿›è¡Œå¤„ç†
            if (result.isFinal && result.text.trim()) {
              console.log("æ”¶åˆ°æœ€ç»ˆè½¬å†™ç»“æœï¼Œå‡†å¤‡å‘é€åˆ°OpenAI:", result.text);
              // æœ€ç»ˆç»“æœåœ¨æ¾å¼€æŒ‰é’®æ—¶ç”±handleTalkButtonUpå¤„ç†
              // è¿™é‡Œåªä¿å­˜ç»“æœ
            }
          },
          // ç¿»è¯‘å›è°ƒ
          (result) => {
            console.log("æ”¶åˆ°Azureç¿»è¯‘ç»“æœ:", result);
            // æ›´æ–°å®æ—¶ç¿»è¯‘
            setRealtimeTranslation(result.translatedText);
            if (result.fromLanguage && result.fromLanguage !== 'unknown') {
              setRealtimeFromLang(result.fromLanguage);
            }
            if (result.toLanguage) {
              setRealtimeToLang(result.toLanguage);
            }
          }
        );
        
        console.log("Azureè¯­éŸ³æœåŠ¡åˆå§‹åŒ–ç»“æœ:", success);
        setAzureInitialized(success);
        
        if (!success) {
          console.warn("Azureè¯­éŸ³æœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼Œåº”ç”¨å°†ä½¿ç”¨OpenAIè¿›è¡Œè½¬å†™å’Œç¿»è¯‘");
          // æ·»åŠ ä¸€ä¸ªé€šçŸ¥æ¶ˆæ¯å‘ŠçŸ¥ç”¨æˆ·
          setTimeout(() => {
            addTranscriptMessage(
              uuidv4().slice(0, 32),
              "assistant",
              "æ³¨æ„ï¼šå®æ—¶è½¬å†™åŠŸèƒ½ä¸å¯ç”¨ï¼Œå°†ä»…ä½¿ç”¨OpenAIè¿›è¡Œè¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘ã€‚"
            );
          }, 2000);
        }
      } catch (error) {
        console.error("åˆå§‹åŒ–Azureè¯­éŸ³æœåŠ¡æ—¶å‡ºç°é”™è¯¯:", error);
        setAzureInitialized(false);
        
        // æ·»åŠ ä¸€ä¸ªé€šçŸ¥æ¶ˆæ¯å‘ŠçŸ¥ç”¨æˆ·
        setTimeout(() => {
          addTranscriptMessage(
            uuidv4().slice(0, 32),
            "assistant",
            "é”™è¯¯ï¼šæ— æ³•åˆå§‹åŒ–å®æ—¶è½¬å†™åŠŸèƒ½ï¼Œå°†ä»…ä½¿ç”¨OpenAIè¿›è¡Œè¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘ã€‚"
          );
        }, 2000);
      }
    };
    
    // åˆå§‹åŒ–è¯­éŸ³æœåŠ¡
    initAzure();
    
    // ç»„ä»¶å¸è½½æ—¶æ¸…ç†èµ„æº
    return () => {
      disposeAzureSpeechService();
    };
  }, []);

  // å½“ä¸»è¯­è¨€æˆ–ç›®æ ‡è¯­è¨€æ›´æ–°æ—¶ï¼Œæ›´æ–°Azureç¿»è¯‘ç›®æ ‡è¯­è¨€
  useEffect(() => {
    if (azureInitialized && lastTargetLang) {
      // å°†è¯­è¨€ä»£ç è½¬æ¢ä¸ºAzureæ ¼å¼
      const getLocaleFromCode = (code: string): string => {
        const localeMap: Record<string, string> = {
          'en': 'en-US',
          'zh': 'zh-CN',
          'es': 'es-ES',
          'fr': 'fr-FR',
          'de': 'de-DE',
          'ja': 'ja-JP',
          'ru': 'ru-RU',
          'ko': 'ko-KR',
          'ar': 'ar-SA',
          'pt': 'pt-BR',
          'it': 'it-IT'
        };
        
        // If it's already a locale format (xx-XX), use it as is
        if (code.includes('-')) return code;
        
        // Otherwise, look up the mapping or use en-US as fallback
        return localeMap[code.toLowerCase()] || 'en-US';
      };
      
      const targetLangCode = getLocaleFromCode(lastTargetLang);
      console.log(`Updating Azure target language to: ${targetLangCode} (from ${lastTargetLang})`);
      
      updateTargetLanguage(targetLangCode);
    }
  }, [azureInitialized, lastTargetLang]);

  // Function to play TTS using Azure's voice synthesis with shimmer turbo voice
  const playTranslationTTS = async (text: string, language: string) => {
    if (!text || !isAudioPlaybackEnabled) return;
    
    try {
      // Don't use TTS for system messages
      if (text.startsWith('ğŸ”Š') || text.startsWith('âš ï¸') || text.startsWith('Please click')) {
        return;
      }
      
      // Convert simple language code to locale format required by TTS
      const getLocaleFromCode = (code: string): string => {
        // Normalize the language code to lowercase
        const normalizedCode = code.toLowerCase();
        
        const localeMap: Record<string, string> = {
          'en': 'en-US',
          'zh': 'zh-CN',
          'es': 'es-ES',
          'fr': 'fr-FR',
          'de': 'de-DE',
          'ja': 'ja-JP',
          'ru': 'ru-RU',
          'ko': 'ko-KR',
          'ar': 'ar-SA',
          'pt': 'pt-BR',
          'it': 'it-IT'
        };
        
        // Handle empty or undefined code
        if (!normalizedCode) {
          console.warn('Empty language code provided, using en-US as fallback');
          return 'en-US';
        }
        
        // If it's already a locale format (xx-XX), use it as is
        if (normalizedCode.includes('-')) return normalizedCode;
        
        // Otherwise, look up the mapping or use en-US as fallback
        const locale = localeMap[normalizedCode] || 'en-US';
        console.log(`Converted language code ${normalizedCode} to locale ${locale}`);
        return locale;
      };
      
      const ttsLocale = getLocaleFromCode(language);
      console.log(`Using Azure TTS with Shimmer voice for: "${text.substring(0, 30)}..." in ${ttsLocale}`);
      
      // Use Azure TTS API as primary option
      try {
        // Call our TTS API endpoint
        console.log(`Sending TTS request with language: ${ttsLocale}`);
        const response = await fetch('/api/tts', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            text: text,
            language: ttsLocale // Use the properly formatted locale
          }),
        });
        
        if (!response.ok) {
          const errorData = await response.json();
          console.error("Azure TTS API error:", errorData);
          throw new Error(errorData.error || `TTS API error: ${response.statusText}`);
        }
        
        // Get the audio data and play it
        const audioData = await response.arrayBuffer();
        if (!audioData || audioData.byteLength === 0) {
          console.error("Received empty audio data from TTS API");
          throw new Error("Empty audio data received");
        }
        
        console.log(`Received audio data: ${audioData.byteLength} bytes`);
        const blob = new Blob([audioData], { type: 'audio/mp3' });
        const url = URL.createObjectURL(blob);
        
        // Create and play audio
        const audio = new Audio(url);
        audio.onerror = (e) => {
          console.error("Audio playback error:", e);
          URL.revokeObjectURL(url);
        };
        audio.onended = () => URL.revokeObjectURL(url);
        
        const playPromise = audio.play();
        if (playPromise !== undefined) {
          playPromise.catch(error => {
            console.error("Error playing audio:", error);
            URL.revokeObjectURL(url);
          });
        }
        
        console.log("Playing Azure TTS audio with Shimmer voice for", ttsLocale);
        return; // Success, no need for fallbacks
      } catch (azureTtsError) {
        console.error("Azure TTS failed:", azureTtsError);
        // Final fallback to Web Speech API if all else fails
        if ('speechSynthesis' in window) {
          console.log("Using Web Speech API as last resort fallback");
          const utterance = new SpeechSynthesisUtterance(text);
          utterance.lang = language; // Use original language code for Web Speech API
          window.speechSynthesis.speak(utterance);
        }
      }
    } catch (error) {
      console.error("Error playing TTS for translation:", error);
      
      // Final fallback to Web Speech API if all else fails
      if ('speechSynthesis' in window) {
        try {
          console.log("Using Web Speech API as last resort fallback");
          const utterance = new SpeechSynthesisUtterance(text);
          utterance.lang = language; // Use original language code for Web Speech API
          window.speechSynthesis.speak(utterance);
        } catch (webSpeechError) {
          console.error("Web Speech API failed:", webSpeechError);
        }
      }
    }
  };

  return (
    <div className="text-base flex flex-col h-screen bg-gray-100 text-gray-800 relative">
      <div className="p-5 text-lg font-semibold flex justify-between items-center">
        <div className="flex items-center">
          <div onClick={() => window.location.reload()} style={{ cursor: 'pointer' }}>
            <Image
              src="/openai-logomark.svg"
              alt="OpenAI Logo"
              width={20}
              height={20}
              className="mr-2"
            />
          </div>
          <div>
            Realtime API <span className="text-gray-500">Agents</span>
          </div>
        </div>
        <div className="flex items-center">
          <div className="bg-gray-200 p-2 rounded-md mr-2">
            <span className="mr-2 font-medium">ML:</span>
            <span>{getFriendlyLanguageName(mainLang)}</span>
          </div>
          <div className="bg-gray-200 p-2 rounded-md">
            <span className="mr-2 font-medium">TL:</span>
            <span>{getFriendlyLanguageName(lastTargetLang)}</span>
          </div>
          <button 
            onClick={() => {
              if (audioElementRef.current) {
                try {
                  console.log("æ‰‹åŠ¨è§¦å‘éŸ³é¢‘æ’­æ”¾");
                  audioElementRef.current.muted = false;
                  setIsAudioPlaybackEnabled(true);
                  const playPromise = audioElementRef.current.play();
                  if (playPromise !== undefined) {
                    playPromise
                      .then(() => console.log("éŸ³é¢‘æ’­æ”¾å·²å¼€å§‹!"))
                      .catch(e => console.error("æ’­æ”¾å‡ºé”™:", e));
                  }
                } catch (e) {
                  console.error("æ‰‹åŠ¨æ’­æ”¾éŸ³é¢‘å¤±è´¥:", e);
                }
              }
            }}
            className="ml-2 bg-white hover:bg-gray-100 text-gray-800 font-semibold py-1 px-2 border border-gray-400 rounded shadow text-xs"
            title="Manually trigger audio playback"
          >
            Play Audio
          </button>
        </div>
        <div className="flex items-center" style={{ display: 'none' }}>
          <label className="flex items-center text-base gap-1 mr-2 font-medium">
            Scenario
          </label>
          <div className="relative inline-block">
            <select
              value={agentSetKey}
              onChange={handleAgentChange}
              className="appearance-none border border-gray-300 rounded-lg text-base px-2 py-1 pr-8 cursor-pointer font-normal focus:outline-none"
              aria-label="é€‰æ‹©åœºæ™¯"
            >
              {Object.keys(allAgentSets).map((agentKey) => (
                <option key={agentKey} value={agentKey}>
                  {agentKey}
                </option>
              ))}
            </select>
            <div className="pointer-events-none absolute inset-y-0 right-0 flex items-center pr-2 text-gray-600">
              <svg className="h-4 w-4" viewBox="0 0 20 20" fill="currentColor">
                <path
                  fillRule="evenodd"
                  d="M5.23 7.21a.75.75 0 011.06.02L10 10.44l3.71-3.21a.75.75 0 111.04 1.08l-4.25 3.65a.75.75 0 01-1.04 0L5.21 8.27a.75.75 0 01.02-1.06z"
                  clipRule="evenodd"
                />
              </svg>
            </div>
          </div>

          {agentSetKey && (
            <div className="flex items-center ml-6">
              <label className="flex items-center text-base gap-1 mr-2 font-medium">
                Agent
              </label>
              <div className="relative inline-block">
                <select
                  value={selectedAgentName}
                  onChange={handleSelectedAgentChange}
                  className="appearance-none border border-gray-300 rounded-lg text-base px-2 py-1 pr-8 cursor-pointer font-normal focus:outline-none"
                  aria-label="é€‰æ‹©ä»£ç†"
                >
                  {selectedAgentConfigSet?.map(agent => (
                    <option key={agent.name} value={agent.name}>
                      {agent.name}
                    </option>
                  ))}
                </select>
                <div className="pointer-events-none absolute inset-y-0 right-0 flex items-center pr-2 text-gray-600">
                  <svg
                    className="h-4 w-4"
                    viewBox="0 0 20 20"
                    fill="currentColor"
                  >
                    <path
                      fillRule="evenodd"
                      d="M5.23 7.21a.75.75 0 011.06.02L10 10.44l3.71-3.21a.75.75 0 111.04 1.08l-4.25 3.65a.75.75 0 01-1.04 0L5.21 8.27a.75.75 0 01.02-1.06z"
                      clipRule="evenodd"
                    />
                  </svg>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>

      <div className="flex flex-1 gap-2 px-2 overflow-hidden relative">
        <Transcript
          userText={userText}
          setUserText={setUserText}
          onSendMessage={handleSendTextMessage}
          canSend={
            sessionStatus === "CONNECTED" &&
            dcRef.current?.readyState === "open"
          }
        />

        <Events isExpanded={isEventsPaneExpanded} />
      </div>

      <BottomToolbar
        sessionStatus={sessionStatus}
        onToggleConnection={onToggleConnection}
        isPTTActive={isPTTActive}
        setIsPTTActive={setIsPTTActive}
        isPTTUserSpeaking={isPTTUserSpeaking}
        handleTalkButtonDown={handleTalkButtonDown}
        handleTalkButtonUp={handleTalkButtonUp}
        isEventsPaneExpanded={isEventsPaneExpanded}
        setIsEventsPaneExpanded={setIsEventsPaneExpanded}
        isAudioPlaybackEnabled={isAudioPlaybackEnabled}
        setIsAudioPlaybackEnabled={setIsAudioPlaybackEnabled}
      />
      
      {/* ç›´æ¥åœ¨DOMä¸­æ”¾ç½®éŸ³é¢‘å…ƒç´ ï¼Œç¡®ä¿å®ƒå§‹ç»ˆå­˜åœ¨ */}
      <audio 
        ref={audioElementRef}
        id="translator-audio-element"
        autoPlay
        playsInline
        style={{ display: "none" }}
      />
      
      {/* æ·»åŠ éŸ³é¢‘æ’­æ”¾çŠ¶æ€æŒ‡ç¤ºå™¨å’Œæ’­æ”¾æŒ‰é’® */}
      {sessionStatus === "CONNECTED" && (
        <div className="fixed top-3 left-1/2 transform -translate-x-1/2 bg-white rounded-full shadow-md px-3 py-1 z-10 flex items-center gap-2">
          <div className={`w-3 h-3 rounded-full ${isAudioPlaybackEnabled ? "bg-green-500" : "bg-red-500"}`}></div>
          <span className="text-sm font-medium">Audio {isAudioPlaybackEnabled ? "Enabled" : "Disabled"}</span>
          {!isAudioPlaybackEnabled && (
            <button 
              className="text-xs bg-blue-500 text-white px-2 py-0.5 rounded hover:bg-blue-600"
              onClick={() => {
                setIsAudioPlaybackEnabled(true);
                if (audioElementRef.current) {
                  audioElementRef.current.muted = false;
                  audioElementRef.current.play().catch(e => console.warn("æ— æ³•è‡ªåŠ¨æ’­æ”¾:", e));
                }
              }}
            >
              å¯ç”¨
            </button>
          )}
        </div>
      )}
    </div>
  );
}

export default App;
